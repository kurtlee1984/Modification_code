{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOR_Pytorch_modification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMK2QDk4VB1kcUtSCC/pPtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurtlee1984/Modification_code/blob/main/YOLOR_Pytorch_modification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyjwfW-ulpi1",
        "outputId": "a7498456-ae85-48ba-8bd2-2243f5cfdb48"
      },
      "source": [
        "# 將Colab與google_drive綁定\n",
        "# 連接到指定帳號,並複製授權碼貼上\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SodQLUbmsapX",
        "outputId": "b2bca3ba-e186-4331-91f4-ca929266a6bc"
      },
      "source": [
        "# 從Github下載YOLOR資料庫\n",
        "\n",
        "!git clone https://github.com/roboflow-ai/yolor\n",
        "%cd yolor\n",
        "!git reset --hard eb3ef0b7472413d6740f5cde39beb1a2f5b8b5d1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolor'...\n",
            "remote: Enumerating objects: 387, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (126/126), done.\u001b[K\n",
            "remote: Total 387 (delta 111), reused 58 (delta 50), pack-reused 210\u001b[K\n",
            "Receiving objects: 100% (387/387), 2.99 MiB | 8.69 MiB/s, done.\n",
            "Resolving deltas: 100% (172/172), done.\n",
            "/content/yolor\n",
            "HEAD is now at eb3ef0b indentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_avGfz9XtjXv",
        "outputId": "00e39836-058c-43b2-b196-ffc672f2928f"
      },
      "source": [
        "# 安裝需求的套件\n",
        "# 並請忽略錯誤\n",
        "\n",
        "!pip install -qr requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 645kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.8MB 22kB/s \n",
            "\u001b[K     |████████████████████████████████| 12.7MB 26.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.0MB/s \n",
            "\u001b[?25h  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.7.0 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcDgWIAStxCP",
        "outputId": "165e0cd3-c900-4640-8c17-62b1becaa155"
      },
      "source": [
        "# 安裝cuda顯卡優化套件\n",
        "\n",
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda\n",
        "!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n",
        "!python setup.py build install\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mish-cuda'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (195/195), 208.77 KiB | 9.94 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "/content/yolor/mish-cuda\n",
            "HEAD is now at 6f38976 Update README.md\n",
            "/usr/lib/python3.7/distutils/extension.py:131: UserWarning: Unknown Extension options: 'headers'\n",
            "  warnings.warn(msg)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/mish_cuda\n",
            "copying src/mish_cuda/__init__.py -> build/lib.linux-x86_64-3.7/mish_cuda\n",
            "running egg_info\n",
            "creating src/mish_cuda.egg-info\n",
            "writing src/mish_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\n",
            "writing requirements to src/mish_cuda.egg-info/requires.txt\n",
            "writing top-level names to src/mish_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'mish_cuda._C' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/csrc\n",
            "creating build/temp.linux-x86_64-3.7/csrc/cpu\n",
            "creating build/temp.linux-x86_64-3.7/csrc/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/CPUApplyUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcsrc/cpu/mish_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcsrc/cuda/mish_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_60,code=sm_60 -std=c++14\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fdebug-prefix-map=/build/python3.7-LSlbJj/python3.7-3.7.11=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "running install\n",
            "running bdist_egg\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-3.7/mish_cuda/__init__.py -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-37.pyc\n",
            "creating stub loader for mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/mish_cuda-0.0.3-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "Extracting mish_cuda-0.0.3-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "mish-cuda 0.0.3 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for mish-cuda==0.0.3\n",
            "Searching for torch==1.7.0\n",
            "Best match: torch 1.7.0\n",
            "Adding torch 1.7.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.19.5\n",
            "Best match: numpy 1.19.5\n",
            "Adding numpy 1.19.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==3.7.4.3\n",
            "Best match: typing-extensions 3.7.4.3\n",
            "Adding typing-extensions 3.7.4.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for dataclasses==0.6\n",
            "Best match: dataclasses 0.6\n",
            "Adding dataclasses 0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for mish-cuda==0.0.3\n",
            "/content/yolor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzXJFjZ6uCYA",
        "outputId": "417ca808-021f-438b-9c7c-641350b4739e"
      },
      "source": [
        "# 安裝pytorch_wavelets圖像分辨率提升套件\n",
        "\n",
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "%cd pytorch_wavelets\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_wavelets'...\n",
            "remote: Enumerating objects: 972, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 972 (delta 75), reused 89 (delta 45), pack-reused 836\u001b[K\n",
            "Receiving objects: 100% (972/972), 6.80 MiB | 31.93 MiB/s, done.\n",
            "Resolving deltas: 100% (659/659), done.\n",
            "/content/yolor/pytorch_wavelets\n",
            "Processing /content/yolor/pytorch_wavelets\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.7.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (3.7.4.3)\n",
            "Building wheels for collected packages: pytorch-wavelets\n",
            "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-cp37-none-any.whl size=54872 sha256=a369f15e9a19e67e97d54445fa87f731e4e2a94d43c7fe9f686099e868325c28\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5brerkqs/wheels/03/e5/53/d1d1a638580a340e426e477d69e8c0b5b5b675209dbdd5e6cb\n",
            "Successfully built pytorch-wavelets\n",
            "Installing collected packages: pytorch-wavelets\n",
            "Successfully installed pytorch-wavelets-1.3.0\n",
            "/content/yolor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uc4_xTPvu1UL"
      },
      "source": [
        "# 轉換當前路徑目錄\n",
        "# 下載資料集,並於google_drive取得壓縮檔的id\n",
        "# id取得方法,到google_drive指定壓縮檔,滑鼠右鍵選擇取得連結,更改權限由限制->知道連結的使用者,複製連結在筆記本上\n",
        "# https://drive.google.com/file/d/這裡就是壓縮檔的id/view?usp=sharing\n",
        "\n",
        "%cd /content\n",
        "!gdown --id '1nswsD6uS07h-rJ9HvQu8VFGNKxyzG37m' -O dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq8DZgPDu3cv"
      },
      "source": [
        "# 解壓縮,注意壓縮檔名稱需與代碼一致\n",
        "# 解壓縮完,於右邊選擇檔案,看有無已解壓縮的資料夾\n",
        "\n",
        "!unzip -q dataset.zip; rm dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hVPz0t-7hf4"
      },
      "source": [
        "# 確定檔案位置和類別數\n",
        "\n",
        "%cd /content\n",
        "%cat data.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2xfAcGw76n8"
      },
      "source": [
        "# 使用以訓練的YOLOR權重\n",
        "\n",
        "%cd /content/yolor\n",
        "!bash scripts/get_pretrain.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ6J5teV8K7h"
      },
      "source": [
        "# 導入yaml解析套件,建構模型屬性\n",
        "\n",
        "import yaml\n",
        "with open('/content/data.yaml') as f:\n",
        "    dataMap = yaml.safe_load(f)\n",
        "\n",
        "num_classes = len(dataMap['names'])\n",
        "num_filters = (num_classes + 5) * 3\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2XOWgwAg5kV"
      },
      "source": [
        "# YOLOR的架構,並可從下方代碼中改寫自己所想要的架構或參數,後寫入yolor_p6.cfg\n",
        "# 若不需要修改,請保持官方設定\n",
        "\n",
        "%%writetemplate /content/yolor/cfg/yolor_p6.cfg\n",
        "\n",
        "[net]\n",
        "batch=64\n",
        "subdivisions=8\n",
        "width=1280\n",
        "height=1280\n",
        "channels=3\n",
        "momentum=0.949\n",
        "decay=0.0005\n",
        "angle=0\n",
        "saturation = 1.5\n",
        "exposure = 1.5\n",
        "hue=.1\n",
        "\n",
        "learning_rate=0.00261\n",
        "burn_in=1000\n",
        "max_batches = 500500\n",
        "policy=steps\n",
        "steps=400000,450000\n",
        "scales=.1,.1\n",
        "\n",
        "mosaic=1\n",
        "\n",
        "\n",
        "# ============ Backbone ============ #\n",
        "\n",
        "# Stem \n",
        "\n",
        "# P1\n",
        "\n",
        "# Downsample\n",
        "\n",
        "# 0\n",
        "[reorg]\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P2\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=64\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=64\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 16 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P3\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=128\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 43 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P4\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=192\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-24\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 70 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=384\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P5\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=256\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 85 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=512\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# P6\n",
        "\n",
        "# Downsample\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Residual Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[shortcut]\n",
        "from=-3\n",
        "activation=linear\n",
        "\n",
        "# Transition first\n",
        "#\n",
        "#[convolutional]\n",
        "#batch_normalize=1\n",
        "#filters=320\n",
        "#size=1\n",
        "#stride=1\n",
        "#pad=1\n",
        "#activation=silu\n",
        "\n",
        "# Merge [-1, -(3k+3)]\n",
        "\n",
        "[route]\n",
        "layers = -1,-12\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 100 (previous+6+3k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=640\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Backbone ============ #\n",
        "\n",
        "# ============ Neck ============ #\n",
        "\n",
        "# CSPSPP\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "### SPP ###\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=5\n",
        "\n",
        "[route]\n",
        "layers=-2\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=9\n",
        "\n",
        "[route]\n",
        "layers=-4\n",
        "\n",
        "[maxpool]\n",
        "stride=1\n",
        "size=13\n",
        "\n",
        "[route]\n",
        "layers=-1,-3,-5,-6\n",
        "### End SPP ###\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -13\n",
        "\n",
        "# 115 (previous+6+5+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# End of CSPSPP\n",
        "\n",
        "\n",
        "# FPN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 85\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 131 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 70\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 147 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# FPN-3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[upsample]\n",
        "stride=2\n",
        "\n",
        "[route]\n",
        "layers = 43\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, -3\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=128\n",
        "activation=silu\n",
        "\n",
        "# Merge [-1, -(2k+2)]\n",
        "\n",
        "[route]\n",
        "layers = -1, -8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 163 (previous+6+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=128\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-4\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 147\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=192\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 176 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=192\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-5\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 131\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 189 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=256\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "\n",
        "# PAN-6\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=2\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1, 115\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# Split\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -2\n",
        "\n",
        "# Plain Block\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=320\n",
        "activation=silu\n",
        "\n",
        "[route]\n",
        "layers = -1,-8\n",
        "\n",
        "# Transition last\n",
        "\n",
        "# 202 (previous+3+4+2k)\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "filters=320\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "activation=silu\n",
        "\n",
        "# ============ End of Neck ============ #\n",
        "\n",
        "# 203\n",
        "[implicit_add]\n",
        "filters=256\n",
        "\n",
        "# 204\n",
        "[implicit_add]\n",
        "filters=384\n",
        "\n",
        "# 205\n",
        "[implicit_add]\n",
        "filters=512\n",
        "\n",
        "# 206\n",
        "[implicit_add]\n",
        "filters=640\n",
        "\n",
        "# 207\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 208\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 209\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# 210\n",
        "[implicit_mul]\n",
        "filters={num_filters}\n",
        "\n",
        "# ============ Head ============ #\n",
        "\n",
        "# YOLO-3\n",
        "\n",
        "[route]\n",
        "layers = 163\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=256\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=203\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=207\n",
        "\n",
        "[yolo]\n",
        "mask = 0,1,2\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-4\n",
        "\n",
        "[route]\n",
        "layers = 176\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=384\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=204\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=208\n",
        "\n",
        "[yolo]\n",
        "mask = 3,4,5\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-5\n",
        "\n",
        "[route]\n",
        "layers = 189\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=512\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=205\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=209\n",
        "\n",
        "[yolo]\n",
        "mask = 6,7,8\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "\n",
        "# YOLO-6\n",
        "\n",
        "[route]\n",
        "layers = 202\n",
        "\n",
        "[convolutional]\n",
        "batch_normalize=1\n",
        "size=3\n",
        "stride=1\n",
        "pad=1\n",
        "filters=640\n",
        "activation=silu\n",
        "\n",
        "[shift_channels]\n",
        "from=206\n",
        "\n",
        "[convolutional]\n",
        "size=1\n",
        "stride=1\n",
        "pad=1\n",
        "filters={num_filters}\n",
        "activation=linear\n",
        "\n",
        "[control_channels]\n",
        "from=210\n",
        "\n",
        "[yolo]\n",
        "mask = 9,10,11\n",
        "anchors = 19,27,  44,40,  38,94,  96,68,  86,152,  180,137,  140,301,  303,264,  238,542,  436,615,  739,380,  925,792\n",
        "classes={num_classes}\n",
        "num=12\n",
        "jitter=.3\n",
        "ignore_thresh = .7\n",
        "truth_thresh = 1\n",
        "random=1\n",
        "scale_x_y = 1.05\n",
        "iou_thresh=0.213\n",
        "cls_normalizer=1.0\n",
        "iou_normalizer=0.07\n",
        "iou_loss=ciou\n",
        "nms_kind=greedynms\n",
        "beta_nms=0.6\n",
        "\n",
        "# ============ End of Head ============ #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTLUV_H09ONa"
      },
      "source": [
        "#讀取yolor資料夾內olor_p6.cfg的模型框架\n",
        "\n",
        "%cat /content/yolor/cfg/yolor_p6.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re3HkQOK-Iwc"
      },
      "source": [
        "# 以自己所需求的epoch數量去訓練ScaledYOLOv4, 可自行修改所需要的epochs數量,這裡是100epochs\n",
        "# 參數說明: img(輸入的圖片尺寸), batch-size(batch大小), epochs(epochs數量), data(.yaml的路徑),cfg(模型架構),\n",
        "#           weights(權重,可修改成自己已訓練的權重路徑),name(結果的名稱), cache(內存與圖像高速緩存)\n",
        "#           device(顯卡的設定) hyp(超參數的設定檔與路徑)\n",
        "\n",
        "%%time\n",
        "%cd /content/yolor\n",
        "!python train.py --batch-size 8 --img 416 416 --data '../data.yaml' --cfg cfg/yolor_p6.cfg --weights '/content/yolor/yolor_p6.pt' --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H74mMhEM-_Sh"
      },
      "source": [
        "# 使用tensorboard可視化套件\n",
        "# 讀取\"runs\"資料夾下的結果\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-EppT3r_AJX"
      },
      "source": [
        "# 導入繪圖與顯示套件\n",
        "from IPython.display import Image\n",
        "from utils.plots import plot_results\n",
        "\n",
        "# 圖片路徑(如果不對記得修改), 繪圖參數\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/results.png', width=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqPqG7S2_cSZ"
      },
      "source": [
        "# 顯示正確Test的照片和其標註的label\n",
        "# 圖片路徑(如果不對記得修改), 繪圖參數\n",
        "\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krzwH1f-_kWg"
      },
      "source": [
        "# 顯示augment後test的照片和其標註的label\n",
        "# 圖片路徑(如果不對記得修改), 繪圖參數\n",
        "\n",
        "print(\"AUGMENTED DATA:\")\n",
        "Image(filename='/content/yolor/runs/train/yolor_p6/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjePKN9Q_qZB"
      },
      "source": [
        "# 已訓練完的權重會存在runs資料夾中, 並檢視檔案與目錄的狀態\n",
        "\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yC__eLLC3sM"
      },
      "source": [
        "# 檢視檔案與目錄的狀態\n",
        "\n",
        "%ls runs/train/yolor_p6/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXpGyMHFECDg"
      },
      "source": [
        "# 為模型創建一個name資料夾\n",
        "\n",
        "import yaml\n",
        "import ast\n",
        "with open(\"../data.yaml\", 'r') as stream:\n",
        "    names = str(yaml.safe_load(stream)['names'])\n",
        "\n",
        "namesFile = open(\"../data.names\", \"w+\")\n",
        "names = ast.literal_eval(names)\n",
        "for name in names:\n",
        "  namesFile.write(name +'\\n')\n",
        "namesFile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pTJOsvwEzbu"
      },
      "source": [
        "# inference存放test資料夾下的照片\n",
        "# 使用訓練時最好的權重,best_overall.pt(需要注意路徑是否正確)\n",
        "\n",
        "!python detect.py --weights \"runs/train/yolor_p6/weights/best_overall.pt\" --conf 0.5 --source ../test/images --names ../data.names --cfg cfg/yolor_p6.cfg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZVPbBxIFIHO"
      },
      "source": [
        "# 顯示出inference後的圖片(需要注意路徑是否正確)\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolor/inference/output/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaqVjuxWFOsL"
      },
      "source": [
        "#下載權重檔案到google_drive中\n",
        "\n",
        "%cp /content/yolor/runs/train/yolor_p6/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}