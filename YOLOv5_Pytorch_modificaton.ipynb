{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv5_Pytorch_modificaton.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPE4pZ759lpuBNcWPZXuESM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurtlee1984/Modification_code/blob/main/YOLOv5_Pytorch_modificaton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjl6W0nD0I72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d175b9-9c85-4aa2-c6b9-556704a28295"
      },
      "source": [
        "# 將Colab與google_drive綁定\n",
        "# 連接到指定帳號,並複製授權碼貼上\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK7Sk0ayF4Ah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feacdb2-3cc5-4a6f-d89c-af6fd24a1546"
      },
      "source": [
        "# 當前設備顯卡參數列表明細:\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jul 23 03:51:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    26W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vua9ZtHN2Hw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86695599-0494-401d-b822-a1d09d66db80"
      },
      "source": [
        "# 從 Github 下載 YOLOv5 的資料庫\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 8338, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 8338 (delta 24), reused 23 (delta 13), pack-reused 8288\u001b[K\n",
            "Receiving objects: 100% (8338/8338), 9.24 MiB | 16.35 MiB/s, done.\n",
            "Resolving deltas: 100% (5764/5764), done.\n",
            "/content/yolov5\n",
            "HEAD is now at 886f1c0 DDP after autoanchor reorder (#2421)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8G4Zyhql2pD2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea453945-f12f-4c43-bd77-425bdc9670a9"
      },
      "source": [
        "# 安裝必要的開發套件與環境\n",
        "!pip install -qr requirements.txt\n",
        "import torch\n",
        "\n",
        "# 顯示圖片的套件\n",
        "from IPython.display import Image, clear_output\n",
        "\n",
        "# 下載模型和資料集的套件\n",
        "from utils.google_utils import gdrive_download\n",
        "\n",
        "# 顯示出當前訓練的配備\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 29.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 36.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30 kB 22.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 61 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 71 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 92 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 102 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 112 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 122 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 133 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 143 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 153 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 163 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 174 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 184 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 194 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 204 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 215 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 225 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 235 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 245 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 256 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 266 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 276 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 286 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 296 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 307 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 317 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 327 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 337 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 348 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 358 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 368 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 378 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 389 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 399 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 409 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 419 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 430 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 440 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 450 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 460 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 471 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 481 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 491 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 501 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 512 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 522 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 532 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 542 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 552 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 563 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 573 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 583 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 593 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 604 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 614 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 624 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 634 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 636 kB 13.8 MB/s \n",
            "\u001b[?25hSetup complete. Using torch 1.9.0+cu102 _CudaDeviceProperties(name='Tesla V100-SXM2-16GB', major=7, minor=0, total_memory=16160MB, multi_processor_count=80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7P6jNwi3jhn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb818a85-521f-42ec-c3cb-25e380694b65"
      },
      "source": [
        "# 下載資料集,並於 google_drive 取得壓縮檔的 id\n",
        "# id 取得方法,到 google_drive 指定壓縮檔,滑鼠右鍵選擇取得連結,更改權限由限制 -> 知道連結的使用者,複製連結在筆記本上\n",
        "# https://drive.google.com/file/d/這裡就是壓縮檔的id/view?usp=sharing\n",
        "\n",
        "%cd /content\n",
        "!gdown --id '15hePnoagt4UJ8bR6XSoKl7rX5OMygub0' -O dataset.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15hePnoagt4UJ8bR6XSoKl7rX5OMygub0\n",
            "To: /content/dataset.zip\n",
            "274MB [00:04, 67.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOgaxopc5JxZ"
      },
      "source": [
        "# 解壓縮,注意壓縮檔名稱需與代碼一致\n",
        "# 解壓縮完,於右邊選擇檔案,看有無已解壓縮的資料夾\n",
        "\n",
        "!unzip -q dataset.zip "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kixzJYfZ5rFg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49dedfb9-381f-47d4-8415-e68567a44281"
      },
      "source": [
        "# 確定類別檔案位置和類別數\n",
        "\n",
        "%cd /content\n",
        "%cat data.yaml"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "nc: 33\n",
            "names: ['bacon', 'bagel', 'baguette', 'baozi', 'burger', 'cereal', 'chips', 'cong_you_bing', 'corn_soup', 'croissant', 'danbing', 'drinks', 'fantuan', 'fried_baozi', 'fried_egg', 'guotie', 'ham', 'hash_brown', 'hotdog', 'pancake', 'radish_cake', 'salad', 'sandwich', 'shaobing', 'sliced_bread', 'steamed_bread', 'tea_egg', 'teppanyaki_noodle', 'triangle_rice_ball', 'waffle', 'water_rice', 'xiaolongbao', 'you_tiao']"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EfhaocL647r"
      },
      "source": [
        "# 根據 data.yaml 來定義訓練的類別數\n",
        "import yaml\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmFFbTeG7QIW",
        "outputId": "d338ad90-0d8f-4799-80f9-44b283750c64",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 從 models 資料夾下抓取 YOLOv5 的架構\n",
        "# 請注意因 YOLOv5 有4個版本,分別是 yolov5s, yolov5m, yolov5l, yolov5x, 請自行修改所需要的架構\n",
        "# 並打印出 YOLOv5 的架構\n",
        "\n",
        "%cat /content/yolov5/models/yolov5s.yaml"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "\n",
            "# anchors\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 9, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
            "   [-1, 3, C3, [1024, False]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5GKjV6J8Dss"
      },
      "source": [
        "# 導入 IPython 套件將方便寫入代碼\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NducSJJU8wfR"
      },
      "source": [
        "# YOLOv5 的架構,並可從下方代碼中改寫自己所想要的架構或參數,後寫入 yolov5.yaml\n",
        "# 請注意因 YOLOv5 有4個版本,分別是 yolov5s, yolov5m, yolov5l, yolov5x, 請自行修改所需要的架構\n",
        "# 若不需要修改,請保持官方設定\n",
        "\n",
        "%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # 類別數\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_oP3NNQ9lTC",
        "outputId": "34306e63-2418-425e-a03b-951dbcf4ab17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 以自己所需求的 epochs 數量去訓練 YOLOv5, 可自行修改所需要的 epochs數量,這裡是 1000 epochs\n",
        "# 參數說明: img(輸入的圖片尺寸), batch( batch 大小), epochs( epochs 數量), data(yaml 的路徑),cfg (模型的架構),\n",
        "#           weights(權重,可修改成自己已訓練的權重路徑), name(結果的名稱), nosave(只存最後的 checkpoint), cache(內存與圖像高速緩存)\n",
        "\n",
        "%%time\n",
        "%cd /content/yolov5/\n",
        "!python train.py --img 416 --batch 16 --epochs 500 --data '../data.yaml' --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/yolov5\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ WARNING: code is out of date by 375 commits. Use 'git pull' to update or 'git clone https://github.com/ultralytics/yolov5' to download latest.\n",
            "YOLOv5 v4.0-126-g886f1c0 torch 1.9.0+cu102 CUDA:0 (Tesla V100-SXM2-16GB, 16160.5MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=16, bucket='', cache_images=True, cfg='./models/custom_yolov5s.yaml', data='../data.yaml', device='', entity=None, epochs=500, evolve=False, exist_ok=False, global_rank=-1, hyp='data/hyp.scratch.yaml', image_weights=False, img_size=[416, 416], linear_lr=False, local_rank=-1, log_artifacts=False, log_imgs=16, multi_scale=False, name='yolov5s_results', noautoanchor=False, nosave=False, notest=False, project='runs/train', quad=False, rect=False, resume=False, save_dir='runs/train/yolov5s_results', single_cls=False, sync_bn=False, total_batch_size=16, weights='', workers=8, world_size=1)\n",
            "\u001b[34m\u001b[1mwandb: \u001b[0mInstall Weights & Biases for YOLOv5 logging with 'pip install wandb' (recommended)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "2021-07-23 03:53:23.287503: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.2, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1    102486  models.yolo.Detect                      [33, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "Model Summary: 283 layers, 7341398 parameters, 7341398 gradients, 17.1 GFLOPS\n",
            "\n",
            "Scaled weight_decay = 0.0005\n",
            "Optimizer groups: 62 .bias, 70 conv.weight, 59 other\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '../train/labels' for images and labels... 11517 found, 0 missing, 0 empty, 0 corrupted: 100% 11517/11517 [00:03<00:00, 3429.54it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: ../train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (1.1GB):  18% 2126/11517 [00:02<00:09, 1040.89it/s]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiOB37DRLDlk"
      },
      "source": [
        "# 使用 tensorboard 可視化套件\n",
        "# 讀取 runs 資料夾下的結果\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD5t6Ti4LWu8"
      },
      "source": [
        "# 導入繪圖與顯示套件\n",
        "from utils.plots import plot_results\n",
        "\n",
        "# 圖片路徑(如果不對記得修改), 繪圖參數\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/results.png', width=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJI5MwbnL3Uh"
      },
      "source": [
        "# 顯示正確 Test 照片和其標註的 label\n",
        "# 圖片路徑(如果不對記得修改), 繪圖參數\n",
        "\n",
        "print(\"GROUND TRUTH TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results2/test_batch2_labels.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y52hLP8kMWcE"
      },
      "source": [
        "# 顯示 augment 後 test 照片和其標註label\n",
        "# 圖片路徑(如果不對記得修改), 繪圖參數\n",
        "\n",
        "print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n",
        "Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZsQMb5iPIWj"
      },
      "source": [
        "# 已訓練完的權重會存在 runs 資料夾中\n",
        "\n",
        "%ls runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jzegas79PbXe"
      },
      "source": [
        "%ls runs/train/yolov5s_results/weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiJ_rY1-Pjhi"
      },
      "source": [
        "# 進行 inference, 存放test資料夾下的照片\n",
        "# 使用訓練時最好的權重, best.pt, (需要注意路徑是否正確)\n",
        "\n",
        "%cd /content/yolov5/\n",
        "!python detect.py --weights runs/train/yolov5s_results/weights/best.pt --img 416 --conf 0.4 --source ../test/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGGwHt-lQTD1"
      },
      "source": [
        "#顯示出 inference 後圖片, (需要注意路徑是否正確)\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'):\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwtpgMO8RWVe"
      },
      "source": [
        "#下載權重檔案到 google_drive 中\n",
        "\n",
        "from google.colab import files\n",
        "files.download('./runs/train/yolov5s_results/weights/best.pt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}